{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QshK8s21WBrf"
   },
   "source": [
    "# Homework07\n",
    "\n",
    "Exercises to practice pandas, data analysis and regression\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Understand the effects of pre-processing data\n",
    "- Get familiar with the ML flow: encode -> normalize -> train -> evaluate\n",
    "- Understand the difference between regression and classification tasks\n",
    "- Build intuition for different regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hf8SXUwWOho"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the following 2 cells to import all necessary libraries and helpers for this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/PSAM-5020-2025F-A/5020-utils/raw/main/src/data_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "\n",
    "from data_utils import object_from_json_url\n",
    "from data_utils import regression_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "Let's load up the full [ANSUR](https://www.openlab.psu.edu/ansur2/) dataset that we looked at briefly in [Week 02](https://github.com/DM-GY-9103-2024F-H/WK02).\n",
    "\n",
    "This is the dataset that has anthropometric information about U.S. Army personnel.\n",
    "\n",
    "#### WARNING\n",
    "\n",
    "Like we mentioned in class, this dataset is being used for these exercises due to the level of detail in the dataset and the rigorous process that was used in collecting the data.\n",
    "\n",
    "This is a very specific dataset and should not be used to draw general conclusions about people, bodies, or anything else that is not related to the distribution of physical features of U.S. Army personnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "ANSUR_FILE = \"https://raw.githubusercontent.com/PSAM-5020-2025F-A/5020-utils/main/datasets/json/ansur.json\"\n",
    "ansur_data = object_from_json_url(ANSUR_FILE)\n",
    "\n",
    "# Look at first 2 records\n",
    "ansur_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested data\n",
    "\n",
    "This is that *nested* dataset from Week 02.\n",
    "\n",
    "# ü§î\n",
    "\n",
    "Let's load it into a `DataFrame` to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into DataFrame\n",
    "ansur_df = pd.DataFrame.from_records(ansur_data)\n",
    "ansur_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# üòìüôÑ\n",
    "\n",
    "That didn't work too well. We ended up with objects in our columns.\n",
    "\n",
    "Luckily, our `DataFrame` library has a function called [`json_normalize()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.json_normalize.html) that can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into DataFrame\n",
    "ansur_df = pd.json_normalize(ansur_data)\n",
    "ansur_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. `DataFrames` are magic.\n",
    "\n",
    "#### Data Exploration\n",
    "\n",
    "Before we start creating models, let's do a little bit of data analysis and get a feeling for the shapes, distributions and relationships of our data.\n",
    "\n",
    "1. Print `min`, `max` and `average` values for all of the features.\n",
    "2. Print `covariance` tables for `age`, `ear.length` and `head.circumference`.\n",
    "3. Plot `age`, `ear.length` and `head.circumference` versus the $1$ *feature* that is most correlated to each of them.\n",
    "\n",
    "Don't forget to *encode* and *normalize* the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Work on Data Exploration here\n",
    "\n",
    "### Encode non-numerical features\n",
    "ansur_encoded_df = ansur_df.copy()\n",
    "\n",
    "non_numeric_cols = ansur_encoded_df.select_dtypes(include=['object']).columns\n",
    "print(\"Non-numeric columns:\", list(non_numeric_cols))\n",
    "\n",
    "if len(non_numeric_cols) > 0:\n",
    "    encoder = OrdinalEncoder().set_output(transform=\"pandas\")\n",
    "    ansur_encoded_df[non_numeric_cols] = encoder.fit_transform(ansur_encoded_df[non_numeric_cols])\n",
    "else:\n",
    "    print(\"No categorical features to encode.\")\n",
    "\n",
    "\n",
    "ansur_num_df = ansur_encoded_df.select_dtypes(include=['number'])\n",
    "\n",
    "## 1. Print min, max, avg\n",
    "\n",
    "for feat in ansur_num_df.columns:\n",
    "    print(f\"{feat}\")\n",
    "    print(f\"\\tmin: {ansur_num_df[feat].min():.3f}\")\n",
    "    print(f\"\\tmax: {ansur_num_df[feat].max():.3f}\")\n",
    "    print(f\"\\tavg: {ansur_num_df[feat].mean():.3f}\")\n",
    "\n",
    "### Normalize all data\n",
    "\n",
    "scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "ansur_scaled_df = scaler.fit_transform(ansur_num_df)\n",
    "display(ansur_scaled_df.head())\n",
    "\n",
    "## 2. Print Covariances\n",
    "\n",
    "features_of_interest = [\"age\", \"ear.length\", \"head.circumference\"]\n",
    "for feat in features_of_interest:\n",
    "    print(f\"\\nCovariance matrix for {feat}:\")\n",
    "    display(ansur_scaled_df.cov()[[feat]].sort_values(by=feat, ascending=False).head(10))\n",
    "\n",
    "## 3. Plot features most correlated to age, ear length and head circumference\n",
    "\n",
    "for feat in features_of_interest:\n",
    "    corr_series = ansur_scaled_df.corr()[feat].drop(labels=[feat])\n",
    "    top_feat = corr_series.abs().idxmax()\n",
    "    print(f\"Feature most correlated with {feat}: {top_feat} (corr={corr_series[top_feat]:.3f})\")\n",
    "\n",
    "\n",
    "    plt.scatter(ansur_scaled_df[top_feat], ansur_scaled_df[feat],\n",
    "                alpha=0.3, marker='o')\n",
    "    plt.xlabel(top_feat)\n",
    "    plt.ylabel(feat)\n",
    "    plt.title(f\"{feat} vs {top_feat}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Does anything stand out about these graphs? Or the correlations?<br>\n",
    "Are correlations symmetric? Does the feature most correlated to ear length also have ear length as its most correlated pair?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>\n",
    "The first graph, age vs ear length, shows a wide spread of points without any strong visible trend. The dots form a dense vertical cluster, meaning that ear length varies across individuals but not systematically with age. There‚Äôs no clear upward or downward slope. People of different ages have roughly similar ear lengths. This could reflect that age isn‚Äôt a determining factor for ear size once adulthood is reached or that the dataset‚Äôs age range doesn‚Äôt capture childhood growth where such changes might occur. Overall, it suggests a very weak or no linear correlation between the two.\n",
    "\n",
    "The second graph, ear length vs weight, shows a clearer diagonal pattern. As weight increases, ear length also tends to increase slightly. The relationship is moderately positive and more consistent than with age, meaning heavier individuals often have somewhat longer ears in this dataset.\n",
    "\n",
    "The third graph, head circumference vs head height, shows the strongest and most linear relationship of all three. The points form a tight diagonal band, suggesting a strong positive correlation. As head height increases, head circumference increases almost proportionally. This is expected since both features relate to head size.\n",
    "\n",
    "These feature pairs were selected based on their highest covariance values from the table above. Each represents the most correlated relationship for its respective variable. Regarding the main question, correlations themselves are symmetric by definition. If ear length is correlated with weight, then weight is equally correlated with ear length. However, the ranking of strongest correlations is not always symmetric. While ear length‚Äôs top correlation might be with weight, weight‚Äôs top correlation might instead be with height or another size-related feature. This explains why correlation symmetry doesn‚Äôt necessarily imply mirrored feature rankings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "Now, we want to create a regression model to predict `head.circumference` from the data.\n",
    "\n",
    "From our [Week 07](https://github.com/PSAM-5020-2025F-A/WK07) notebook, we can create a regression model by following these steps:\n",
    "\n",
    "1. Load dataset (done! üéâ)\n",
    "2. Encode label features as numbers (done! ‚ö°Ô∏è)\n",
    "3. Normalize the data (done! üçæ)\n",
    "4. Separate the outcome variable and the input features\n",
    "5. Create a regression model using all features\n",
    "6. Run model on training data and measure error\n",
    "7. Plot predictions and interpret results\n",
    "8. Run model on test data, measure error, plot predictions, interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Work on Regression Model here\n",
    "\n",
    "## Separate outcome variable and input features\n",
    "\n",
    "outcome = ansur_num_df[\"head.circumference\"]\n",
    "features = ansur_scaled_df.drop(columns=[\"head.circumference\"])\n",
    "\n",
    "## Create a regression model\n",
    "head_model = LinearRegression().fit(features, outcome)\n",
    "\n",
    "## Measure error on training data\n",
    "predicted_head = head_model.predict(features)\n",
    "regression_error(outcome, predicted_head)\n",
    "\n",
    "print(\"Training error:\")\n",
    "print(regression_error(outcome, predicted_head))\n",
    "\n",
    "## Plot predictions and interpret results\n",
    "head_original = outcome\n",
    "plt.plot(sorted(head_original), marker='o', linestyle='', alpha=0.3)\n",
    "plt.plot(sorted(predicted_head), color='r', marker='o', markersize='3', linestyle='', alpha=0.1)\n",
    "plt.ylabel(\"head.circumference\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Test Data\n",
    "ANSUR_TEST_FILE = \"https://raw.githubusercontent.com/PSAM-5020-2025F-A/5020-utils/main/datasets/json/ansur-test.json\"\n",
    "\n",
    "ansur_test_data = object_from_json_url(ANSUR_TEST_FILE)\n",
    "ansur_test_df = pd.json_normalize(ansur_test_data)\n",
    "\n",
    "ansur_test_encoded_df = ansur_test_df.copy()\n",
    "\n",
    "g_vals = encoder.transform(ansur_test_df[[\"gender\"]].values)\n",
    "ansur_test_encoded_df[[\"gender\"]] = g_vals\n",
    "\n",
    "ansur_test_scaled_df = scaler.transform(ansur_test_encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Run model on test data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, outcome_train, outcome_test = train_test_split(\n",
    "    features, outcome, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "head_model = LinearRegression().fit(features_train, outcome_train)\n",
    "\n",
    "\n",
    "## Measure error on test data\n",
    "\n",
    "predicted_test = head_model.predict(features_test)\n",
    "regression_error(outcome_test, predicted_test)\n",
    "\n",
    "## Plot predictions and interpret results\n",
    "plt.plot(sorted(outcome_test), marker='o', linestyle='', alpha=0.3)\n",
    "plt.plot(sorted(predicted_test), color='r', marker='o', markersize='3', linestyle='', alpha=0.1)\n",
    "plt.ylabel(\"head.circumference\")\n",
    "plt.title(\"Test Data: Actual vs Predicted Head Circumference\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "How well does your model perform?<br>\n",
    "How could you improve it?<br>\n",
    "Are there ranges of circumferences that don't get predicted well?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>\n",
    "My model performs quite well overall. The training and test results both show very similar curves, which means the regression model has successfully captured the main linear relationships in the ANSUR dataset. The predicted values follow the same general pattern as the actual head circumference values, only with a smoother line. This smoothness makes sense because linear regression fits an average trend through the data rather than trying to match every small fluctuation. The fact that the test results look almost identical to the training results also shows that the model generalizes well and isn‚Äôt overfitting the data.\n",
    "\n",
    "When I look closely at the plots, the model performs best across the middle range of head circumferences, where the majority of data points lie. However, the predictions become less accurate toward the extremes. For very small head circumferences, the model tends to overestimate and for very large ones, it slightly underestimates. This happens because there are fewer samples at the tails of the dataset and a simple linear model cannot bend to capture any non-linear relationships that might exist there. In other words, it pulls the extreme values toward the mean.\n",
    "\n",
    "To improve the model, I could introduce non-linear features using polynomial terms so that it can better capture curvature at the extremes. Adding squared terms or interactions between key body measurements (like height, weight and head length) would allow the model to account for more complex relationships. \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
